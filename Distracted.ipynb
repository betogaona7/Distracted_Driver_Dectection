{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distracted.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/betogaona7/Distracted_Driver_Detection/blob/master/Distracted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHHZJUxGa08N",
        "colab_type": "text"
      },
      "source": [
        "## Connect with Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq5bdOPEakdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/betogaona7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmNyou92atnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ./../betogaona7/My\\ Drive/app/Distracted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7fTEx2bC32",
        "colab_type": "text"
      },
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL2NkIhYbA0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import random\n",
        "from PIL import Image \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jSWxOnbbFSn",
        "colab_type": "text"
      },
      "source": [
        "## Create train and validation TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugDfG9V2lT9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imgs_with_labels(src):\n",
        "  data = []\n",
        "  total = 0\n",
        "  for path, subdir, files in os.walk(src):\n",
        "    for file in files:\n",
        "      if file[-3:] == 'jpg': \n",
        "        data.append((os.path.join(path, file), path[-1:]))\n",
        "      total += 1\n",
        "  return data, total\n",
        "\n",
        "data, total = imgs_with_labels(\"./data/test/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owYTFog5vigm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(total)\n",
        "img_path, label = data[random.randint(0, total)]\n",
        "print(\"img: \", img_path, \" label: \", label, \" total: \", total )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi84VKBor1ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data[:10])\n",
        "random.shuffle(data)\n",
        "print(data[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTWaqSYzrkWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = 22424\n",
        "\n",
        "tsize = int(0.8*total)+1\n",
        "vsize = int(0.2*total)\n",
        "\n",
        "train_data = data[:tsize]\n",
        "valid_data = data[-vsize:]\n",
        "\n",
        "print(len(train_data), len(valid_data), tsize+vsize)\n",
        "print(train_data[-10:])\n",
        "print(valid_data[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQSp7kjKl_xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def create_tf_record(tfr_name, data):\n",
        "  writer = tf.python_io.TFRecordWriter(tfr_name)\n",
        "  i = 1\n",
        "  for img_path, img_class in data:\n",
        "    img = np.array(Image.open(img_path))\n",
        "\n",
        "    img_raw = open(img_path, 'rb').read()\n",
        "    label = int(img_class)\n",
        "    path = str.encode(img_path)\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image': _bytes_feature(img_raw),\n",
        "        'label': _int64_feature(label),\n",
        "        'height': _int64_feature(img.shape[0]),\n",
        "        'width': _int64_feature(img.shape[1]),\n",
        "        'depth': _int64_feature(img.shape[2]),\n",
        "        'path': _bytes_feature(path) }))\n",
        "    writer.write(example.SerializeToString())\n",
        "    if(i%100 == 0):\n",
        "        print(i)\n",
        "    i+= 1\n",
        "  writer.close()\n",
        "  \n",
        "#create_tf_record(\"train2.tfrecord\", train_data)\n",
        "#create_tf_record(\"valid2.tfrecord\", valid_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqsWpGPNupua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example in tf.python_io.tf_record_iterator(\"train.tfrecord\"):\n",
        "  result = tf.train.Example.FromString(example)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLl_WRcY3tmt",
        "colab_type": "code",
        "outputId": "87e3df2d-2f4d-4fbd-e76f-42c334717001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!du -lh valid.tfrecord\n",
        "!du -lh train.tfrecord\n",
        "!du -sh ./data/train/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91M\tvalid.tfrecord\n",
            "820M\ttrain.tfrecord\n",
            "913M\t./data/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3QcMMXjA1m3",
        "colab_type": "code",
        "outputId": "17d3580f-d3ab-43af-f380-47b91eb56fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!du -lh test.tfrecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "du: cannot access 'test.tfrecord': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvnwbEyO_tvX",
        "colab_type": "text"
      },
      "source": [
        "## Build dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LHNp5RZ8g9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def StateFarmDataset(image_size, tfrecord_file, shuffle_buffer_size, batch_size):\n",
        "  img_size = tf.cast(image_size, tf.int32)\n",
        "  \n",
        "  def _parse_function(example):\n",
        "    features = {'label': tf.FixedLenFeature((), tf.int64),\n",
        "                'image': tf.FixedLenFeature((), tf.string),\n",
        "                'height': tf.FixedLenFeature((), tf.int64),\n",
        "                'width': tf.FixedLenFeature((), tf.int64),\n",
        "                'depth': tf.FixedLenFeature((), tf.int64),\n",
        "                'path': tf.FixedLenFeature((), tf.string)}\n",
        "    parsed_features = tf.parse_single_example(example, features)\n",
        "    \n",
        "    # Reconstruct image \n",
        "    image = tf.image.decode_jpeg(parsed_features['image'], 3)\n",
        "    img_shape = tf.stack([tf.cast(parsed_features['height'], tf.int32),\n",
        "                          tf.cast(parsed_features['width'], tf.int32),\n",
        "                          tf.cast(parsed_features['depth'], tf.int32)])\n",
        "    image = tf.reshape(image, img_shape)\n",
        "    \n",
        "    # Normalize the image in the range 0 to 1\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    # Reshape image \n",
        "    image = tf.image.resize(image, [image_size, image_size])\n",
        "        \n",
        "    # One-hot encoding\n",
        "    label = tf.one_hot(parsed_features['label'], 10, dtype=tf.int32)\n",
        "    \n",
        "    return image, label, parsed_features['path']\n",
        "  \n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "  dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  \n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  \n",
        "  return dataset         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZYHZQOFZ7Y",
        "colab_type": "code",
        "outputId": "5ea79551-c5c6-4535-a7cb-75179982d9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = 22424\n",
        "dataset = StateFarmDataset(64, \"train2.tfrecord\", total, 1)\n",
        "print(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 64, 64, ?), (?, 10), (?,)), types: (tf.float32, tf.int32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobVutrvFu33",
        "colab_type": "code",
        "outputId": "2e9b97ad-53ca-495d-a518-36e9551da17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "def test_normalization(image):\n",
        "  assert image.max() <= 1 and image.min() >= 0,\\\n",
        "        'Incorect Range. {} to {} found'.format(image().min(), image.to_numpy().max())\n",
        "  print(\"Fine.\")\n",
        "    \n",
        "\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "record = iterator.get_next()\n",
        "with tf.Session() as sess:\n",
        "  img, label, img_path = sess.run(record)\n",
        "  print(\"Label: \", label)\n",
        "  print(\"Img path: \", img_path)\n",
        "  print(\"Img shape: \", img.shape)\n",
        "  test_normalization(img[0])\n",
        "  #print(img)\n",
        "  plt.imshow(img[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  [[0 0 0 0 0 0 1 0 0 0]]\n",
            "Img path:  [b'./data/train/c6/img_97195.jpg']\n",
            "Img shape:  (1, 64, 64, 3)\n",
            "Fine.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8C0syhD2wbewKEPYB9/Cogzx/wEyyAjW4QOijwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mwmueSikRfZ",
        "colab_type": "code",
        "outputId": "be0aa6c7-9e6b-41b6-8525-3d07db77487c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_samples = 17943\n",
        "valid_samples =  4481\n",
        "img_size = 64\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = StateFarmDataset(img_size, \"train2.tfrecord\", train_samples, batch_size)\n",
        "valid_dataset = StateFarmDataset(img_size, \"valid2.tfrecord\", valid_samples, valid_samples)\n",
        "\n",
        "handle = tf.placeholder(tf.string, shape=[])\n",
        "train_iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
        "next_train_elements = train_iterator.get_next()\n",
        "train_iter = train_dataset.make_initializable_iterator()\n",
        "\n",
        "valid_iterator = valid_dataset.make_one_shot_iterator()\n",
        "next_valid_elements = valid_iterator.get_next()\n",
        "\n",
        "\n",
        "print(\"Samples in training: \", train_samples, \"Number of trainining mini-batches: \", int(train_samples/batch_size))\n",
        "print(\"Samples in validation: \", valid_samples, \"Number of validation mini-batches: \", int(valid_samples/valid_samples))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples in training:  17943 Number of trainining mini-batches:  140\n",
            "Samples in validation:  4481 Number of validation mini-batches:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49qUeQAFilxG",
        "colab_type": "text"
      },
      "source": [
        "## Build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ynlm9ICKblS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_input(img_shape):\n",
        "  return tf.placeholder(tf.float32, shape=[None, img_shape[0], img_shape[1], img_shape[2]], name=\"x\")\n",
        "\n",
        "def nn_label(n_classes):\n",
        "  return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
        "\n",
        "def nn_keep_prob():\n",
        "  return tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "def conv2d_maxpool(x_tensor, outs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
        "  weights = tf.Variable(tf.truncated_normal([conv_ksize, conv_ksize, int(x_tensor.shape[3]), outs]))\n",
        "  bias = tf.Variable(tf.zeros([outs]))\n",
        "  \n",
        "  x = tf.nn.conv2d(x_tensor, weights, strides=[1, conv_strides, conv_strides, 1], padding=\"SAME\")\n",
        "  x = tf.nn.bias_add(x, bias)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.nn.max_pool(x, ksize=[1, pool_ksize, pool_ksize, 1], strides=[1, pool_strides, pool_strides, 1], padding=\"SAME\")\n",
        "  return x\n",
        "\n",
        "def flatten(x_tensor):\n",
        "  dimensions = x_tensor.get_shape().as_list()\n",
        "  img_flat_size = dimensions[1] * dimensions[2] * dimensions[3]\n",
        "  return tf.reshape(x_tensor, [-1, img_flat_size])\n",
        "\n",
        "def dense(x_tensor, n_outputs):\n",
        "  weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), n_outputs], mean=0.0, stddev=0.1))\n",
        "  bias = tf.Variable(tf.zeros([n_outputs]))\n",
        "  \n",
        "  x = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "  x = tf.nn.relu(x)\n",
        "  return x\n",
        "\n",
        "def nn_output(x_tensor, n_outputs):\n",
        "  weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), n_outputs], mean=0.0, stddev=0.1))\n",
        "  bias = tf.Variable(tf.zeros([n_outputs]))\n",
        "  \n",
        "  x = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMa5bVQ6cwSG",
        "colab_type": "text"
      },
      "source": [
        "### Unit tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG5ov2thbf8e",
        "colab_type": "code",
        "outputId": "5790b255-0ff8-4f2b-afe9-311f97fc603a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "def test_nn_input(neural_net_image_input):\n",
        "    image_shape = (64, 64, 3)\n",
        "    nn_inputs_out_x = nn_input(image_shape)\n",
        "\n",
        "    assert nn_inputs_out_x.get_shape().as_list() == [None, image_shape[0], image_shape[1], image_shape[2]],\\\n",
        "        'Incorrect Image Shape.  Found {} shape'.format(nn_inputs_out_x.get_shape().as_list())\n",
        "\n",
        "    assert nn_inputs_out_x.op.type == 'Placeholder',\\\n",
        "        'Incorrect Image Type.  Found {} type'.format(nn_inputs_out_x.op.type)\n",
        "\n",
        "    assert nn_inputs_out_x.name == 'x:0', \\\n",
        "        'Incorrect Name.  Found {}'.format(nn_inputs_out_x.name)\n",
        "\n",
        "    print(\"Image input tests passed.\")\n",
        "\n",
        "\n",
        "def test_nn_label(neural_net_label_input):\n",
        "    n_classes = 10\n",
        "    nn_inputs_out_y = nn_label(n_classes)\n",
        "\n",
        "    assert nn_inputs_out_y.get_shape().as_list() == [None, n_classes],\\\n",
        "        'Incorrect Label Shape.  Found {} shape'.format(nn_inputs_out_y.get_shape().as_list())\n",
        "\n",
        "    assert nn_inputs_out_y.op.type == 'Placeholder',\\\n",
        "        'Incorrect Label Type.  Found {} type'.format(nn_inputs_out_y.op.type)\n",
        "\n",
        "    assert nn_inputs_out_y.name == 'y:0', \\\n",
        "        'Incorrect Name.  Found {}'.format(nn_inputs_out_y.name)\n",
        "\n",
        "    print(\"Label input tests passed.\")\n",
        "    \n",
        "def test_nn_keep_prob(neural_net_keep_prob_input):\n",
        "    nn_inputs_out_k = nn_keep_prob()\n",
        "\n",
        "    assert nn_inputs_out_k.get_shape().ndims is None,\\\n",
        "        'Too many dimensions found for keep prob.  Found {} dimensions.  It should be a scalar (0-Dimension Tensor).'.format(nn_inputs_out_k.get_shape().ndims)\n",
        "\n",
        "    assert nn_inputs_out_k.op.type == 'Placeholder',\\\n",
        "        'Incorrect keep prob Type.  Found {} type'.format(nn_inputs_out_k.op.type)\n",
        "\n",
        "    assert nn_inputs_out_k.name == 'keep_prob:0', \\\n",
        "        'Incorrect Name.  Found {}'.format(nn_inputs_out_k.name)\n",
        "    \n",
        "    print(\"Keep prob tests passed.\")\n",
        "    \n",
        "def test_conv2d_maxpool(conv2d_maxpool):\n",
        "    test_x = tf.placeholder(tf.float32, [None, 64, 64, 5])\n",
        "    test_num_outputs = 10\n",
        "    test_con_k = 2\n",
        "    test_con_s = 4\n",
        "    test_pool_k = 2\n",
        "    test_pool_s = 2\n",
        "\n",
        "    conv2d_maxpool_out = conv2d_maxpool(test_x, test_num_outputs, test_con_k, test_con_s, test_pool_k, test_pool_s)\n",
        "\n",
        "    assert conv2d_maxpool_out.get_shape().as_list() == [None, 8, 8, 10],\\\n",
        "        'Incorrect Shape.  Found {} shape'.format(conv2d_maxpool_out.get_shape().as_list())\n",
        "\n",
        "    print(\"Conv layer test passed.\")\n",
        "    \n",
        "def test_flatten(flatten):\n",
        "    test_x = tf.placeholder(tf.float32, [None, 10, 30, 6])\n",
        "    flat_out = flatten(test_x)\n",
        "\n",
        "    assert flat_out.get_shape().as_list() == [None, 10*30*6],\\\n",
        "        'Incorrect Shape.  Found {} shape'.format(flat_out.get_shape().as_list())\n",
        "\n",
        "    print(\"Flatten test passed.\")\n",
        "    \n",
        "def test_dense(fully_conn):\n",
        "    test_x = tf.placeholder(tf.float32, [None, 128])\n",
        "    test_num_outputs = 40\n",
        "\n",
        "    fc_out = fully_conn(test_x, test_num_outputs)\n",
        "\n",
        "    assert fc_out.get_shape().as_list() == [None, 40],\\\n",
        "        'Incorrect Shape.  Found {} shape'.format(fc_out.get_shape().as_list())\n",
        "\n",
        "    print(\"Dense layer test passed.\")\n",
        "\n",
        "\n",
        "def test_output(output):\n",
        "    test_x = tf.placeholder(tf.float32, [None, 128])\n",
        "    test_num_outputs = 40\n",
        "\n",
        "    output_out = output(test_x, test_num_outputs)\n",
        "\n",
        "    assert output_out.get_shape().as_list() == [None, 40],\\\n",
        "        'Incorrect Shape.  Found {} shape'.format(output_out.get_shape().as_list())\n",
        "\n",
        "    print(\"Output test passed\")\n",
        "\n",
        "test_nn_input(nn_input)\n",
        "test_nn_label(nn_label)\n",
        "test_nn_keep_prob(nn_keep_prob)\n",
        "test_conv2d_maxpool(conv2d_maxpool)\n",
        "test_flatten(flatten)\n",
        "test_dense(dense)\n",
        "test_output(nn_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image input tests passed.\n",
            "Label input tests passed.\n",
            "Keep prob tests passed.\n",
            "Conv layer test passed.\n",
            "Flatten test passed.\n",
            "Dense layer test passed.\n",
            "Output test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvHqNlk0Msl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(x, keep_prob):\n",
        "  conv1 = conv2d_maxpool(x, 128, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv2 = conv2d_maxpool(conv1, 64, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv3 = conv2d_maxpool(conv2, 32, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv4 = conv2d_maxpool(conv3, 16, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  \n",
        "  fc1 = flatten(conv4)\n",
        "  fc1 = dense(fc1, 1024)\n",
        "  \n",
        "  out = nn_output(fc1, 10)\n",
        "  return out \n",
        "\n",
        "x = nn_input((64, 64, 3))\n",
        "y = nn_label(10)\n",
        "keep_prob = nn_keep_prob()\n",
        "\n",
        "logits = model(x, keep_prob)\n",
        "logits = tf.identity(logits, name=\"logits\")\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3sqXQrhS82",
        "colab_type": "code",
        "outputId": "7611ccd5-e1a5-4b84-9e64-c24666d54d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_model(model):\n",
        "    test_x = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
        "    test_k = tf.placeholder(tf.float32)\n",
        "\n",
        "    logits_out = model(test_x, test_k)\n",
        "\n",
        "    assert logits_out.get_shape().as_list() == [None, 10],\\\n",
        "        'Incorrect Model Output.  Found {}'.format(logits_out.get_shape().as_list())\n",
        "\n",
        "    print(\"Model test passed.\")\n",
        "    \n",
        "test_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DhpKlR55t88",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG3a7xeVlGIi",
        "colab_type": "code",
        "outputId": "441a0db7-af8f-494e-88c1-03c7ef941eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not tf.test.gpu_device_name():\n",
        "  print(\"You don't have the GPU activated\")\n",
        "else:\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJf8zWtV5y_I",
        "colab_type": "text"
      },
      "source": [
        "### Single optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drIDmI3Z3fB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn(session, optimizer, keep_probability, feature_batch, label_batch):\n",
        "  return session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
        "\n",
        "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
        "  loss = sess.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
        "  \n",
        "  valid_acc = sess.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
        "  print(\"Loss: {:>10.4f} Validation accuracy: {:.6f}\".format(loss, valid_acc))\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvA7VA2_i7Ql",
        "colab_type": "code",
        "outputId": "aa6b9abe-d299-4d81-aca6-103d7d50800f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from unittest.mock import MagicMock\n",
        "\n",
        "def test_train_nn(train_neural_network):\n",
        "    mock_session = tf.Session()\n",
        "    test_x = np.random.rand(128, 64, 64, 3)\n",
        "    test_y = np.random.rand(128, 10)\n",
        "    test_k = np.random.rand(1)\n",
        "    test_optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "    mock_session.run = MagicMock()\n",
        "    train_neural_network(mock_session, test_optimizer, test_k, test_x, test_y)\n",
        "\n",
        "    assert mock_session.run.called, 'Session not used'\n",
        "\n",
        "    print(\"Training test passed.\")\n",
        "    \n",
        "test_train_nn(train_nn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZyW-sMz7kH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 15 \n",
        "keep_probability = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hffgzEaURhp9",
        "colab_type": "code",
        "outputId": "1b6b0465-19e8-498f-f2b3-d69615043096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Checking training on a single mini batch... \")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  train_handle = sess.run(train_iter.string_handle())\n",
        "  sess.run(train_iter.initializer)\n",
        "  \n",
        "  valid_features, valid_labels,_ = sess.run(next_valid_elements)\n",
        "  features, labels, _ = sess.run(next_train_elements, feed_dict={handle: train_handle}) # First mini batch\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    batch_i = 1\n",
        "    train_nn(sess, optimizer, keep_probability, features, labels)\n",
        "    print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "    print_stats(sess, valid_features, valid_labels, cost, accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking training on a single mini batch... \n",
            "Epoch  1, Batch 1:  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB7A1SkraOpV",
        "colab_type": "text"
      },
      "source": [
        "## Full train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw-Cv3R4CmyN",
        "colab_type": "code",
        "outputId": "4bbc6f81-bf27-4b75-fa9a-06ef39626b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "print(\"Training...\")\n",
        "\n",
        "with tf.Session() as  sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  train_handle = sess.run(train_iter.string_handle())\n",
        "  \n",
        "  \n",
        "  valid_features, valid_labels,_ = sess.run(next_valid_elements)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    sess.run(train_iter.initializer)\n",
        "    for batch in range(158):\n",
        "      features, labels, _ = sess.run(next_train_elements, feed_dict={handle: train_handle})\n",
        "      train_nn(sess, optimizer, keep_probability, features, labels)\n",
        "    print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, 1), end='')\n",
        "    print_stats(sess, valid_features, valid_labels, cost, accuracy)\n",
        "    \n",
        "  saver = tf.train.Saver()\n",
        "  save_path = saver.save(sess, \"./model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  2, Batch 1:  Loss:   152.9061 Validation accuracy: 0.748885\n",
            "Epoch  3, Batch 1:  Loss:    99.1391 Validation accuracy: 0.830508\n",
            "Epoch  4, Batch 1:  Loss:    83.0813 Validation accuracy: 0.844781\n",
            "Epoch  5, Batch 1:  Loss:    61.5902 Validation accuracy: 0.884478\n",
            "Epoch  6, Batch 1:  Loss:    60.7555 Validation accuracy: 0.893399\n",
            "Epoch  7, Batch 1:  Loss:    65.3486 Validation accuracy: 0.884032\n",
            "Epoch  8, Batch 1:  Loss:    58.1882 Validation accuracy: 0.893845\n",
            "Epoch  9, Batch 1:  Loss:    68.6058 Validation accuracy: 0.876896\n",
            "Epoch 10, Batch 1:  Loss:    40.7528 Validation accuracy: 0.921053\n",
            "Epoch 11, Batch 1:  Loss:    40.5651 Validation accuracy: 0.919715\n",
            "Epoch 12, Batch 1:  Loss:    47.2211 Validation accuracy: 0.918822\n",
            "Epoch 13, Batch 1:  Loss:    36.6121 Validation accuracy: 0.931311\n",
            "Epoch 14, Batch 1:  Loss:    37.8650 Validation accuracy: 0.937110\n",
            "Epoch 15, Batch 1:  Loss:    40.6515 Validation accuracy: 0.935326\n",
            "Epoch 16, Batch 1:  Loss:    33.6616 Validation accuracy: 0.946922\n",
            "Epoch 17, Batch 1:  Loss:    56.2697 Validation accuracy: 0.909010\n",
            "Epoch 18, Batch 1:  Loss:    39.1968 Validation accuracy: 0.937556\n",
            "Epoch 19, Batch 1:  Loss:    37.0022 Validation accuracy: 0.946476\n",
            "Epoch 20, Batch 1:  Loss:    61.5578 Validation accuracy: 0.914362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Esg0l5hBBd",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhLo8lCDaFvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example in tf.python_io.tf_record_iterator(\"test.tfrecord\"):\n",
        "  result = tf.train.Example.FromString(example)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w83ldRALcEKv",
        "colab_type": "code",
        "outputId": "a842e259-b97d-4c83-828c-dd38238fe398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_test_data(image_size, tfrecord_file, batch_size):\n",
        "  img_size = tf.cast(image_size, tf.int32)\n",
        "  \n",
        "  def _parse_function(example):\n",
        "    features = {'image': tf.FixedLenFeature((), tf.string),\n",
        "                'height': tf.FixedLenFeature((), tf.int64),\n",
        "                'width': tf.FixedLenFeature((), tf.int64),\n",
        "                'depth': tf.FixedLenFeature((), tf.int64),\n",
        "                'path': tf.FixedLenFeature((), tf.string)}\n",
        "    parsed_features = tf.parse_single_example(example, features)\n",
        "    \n",
        "    # Reconstruct image \n",
        "    image = tf.image.decode_jpeg(parsed_features['image'], 3)\n",
        "    img_shape = tf.stack([tf.cast(parsed_features['height'], tf.int32),\n",
        "                          tf.cast(parsed_features['width'], tf.int32),\n",
        "                          tf.cast(parsed_features['depth'], tf.int32)])\n",
        "    image = tf.reshape(image, img_shape)\n",
        "    \n",
        "    # Normalize the image in the range 0 to 1\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    # Reshape image \n",
        "    image = tf.image.resize(image, [image_size, image_size])\n",
        "    \n",
        "    return image, parsed_features['path']\n",
        "  \n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  \n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  \n",
        "  return dataset        \n",
        "\n",
        "test_data = get_test_data(64, \"test.tfrecord\", 128)\n",
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 45, 60, ?), (?,)), types: (tf.float32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2zXCnKtUTgT",
        "colab_type": "text"
      },
      "source": [
        "### Display a single test image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-rC-Mx_ZA79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterator = test_data.make_one_shot_iterator()\n",
        "record = iterator.get_next()\n",
        "with tf.Session() as sess:\n",
        "  img, img_path = sess.run(record)\n",
        "  print(\"Img path: \", img_path)\n",
        "  print(\"Img shape: \", img.shape)\n",
        "  plt.imshow(img[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2UIVQLfVWQq",
        "colab_type": "text"
      },
      "source": [
        "### Build test iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHzzEK2dVVaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = get_test_data(64, \"test.tfrecord\", 1)\n",
        "\n",
        "handle = tf.placeholder(tf.string, shape=[])\n",
        "\n",
        "test_iterator = tf.data.Iterator.from_string_handle(handle, test_dataset.output_types, test_dataset.output_shapes)\n",
        "next_test_elements = train_iterator.get_next()\n",
        "test_iter = test_dataset.make_initializable_iterator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HI2d5YVZZ-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model_path=\"./model\"\n",
        "n_samples = 3\n",
        "top_n_predictions = 3\n",
        "\n",
        "def get_predictions():\n",
        "  img_predictionsp = []\n",
        "  loaded_graph = tf.Graph()\n",
        "  with tf.Session(graph=loaded_graph) as sess:\n",
        "    # Load model \n",
        "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "    loader.restore(sess, saved_model_path)\n",
        "    \n",
        "    # Get tensor from loaded model\n",
        "    loaded_x = loaded_graph.get_tensor_by_name(\"x:0\")\n",
        "    loaded_y = loaded_graph.get_tensor_by_name(\"y:0\")\n",
        "    loaded_keep_prob = loaded_graph.get_tensor_by_name(\"keep_prob:0\")\n",
        "    loaded_logits = loaded_graph.get_tensor_by_name(\"logits:0\")\n",
        "    loaded_acc = loaded_graph.get_tensor_by_name(\"accuracy:0\")\n",
        "    \n",
        "    # Initialize batch iterator\n",
        "    test_handle = sess.run(test_iter.string_handle())\n",
        "    sess.run(test_iter.initializer)\n",
        "    \n",
        "    for testsample in range(79726):\n",
        "      image, image_name = sess.run(next_test_elements, feed_dict={handle: test_handle})\n",
        "      image_predictions = sess.run(tf.nn.softmax(loaded_logits), feed_dict={loaded_x: images,\n",
        "                                                                            loaded_y: None,\n",
        "                                                                            loadedl_keep_prob: 1.0}\n",
        "      print(image_name,  predictions.shape)\n",
        "      print(predictions)\n",
        "      break\n",
        "                               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTV-9H_ah32q",
        "colab_type": "text"
      },
      "source": [
        "### Save CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn_sCb1gBkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('predictions.csv', 'w', newline='') as csvfile:\n",
        "  doc = csv.writer(csvfile)\n",
        "  doc.writerow(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
        "  for i in range(79726):\n",
        "    doc.writerow([t[i][0], t[i][1], t[i][2], t[i][3], t[i][4], t[i][5], t[i][6], t[i][7], t[i][8],\n",
        "                  t[i][9], t[i][10], t[i][11]])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}