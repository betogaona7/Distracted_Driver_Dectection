{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distracted.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHHZJUxGa08N",
        "colab_type": "text"
      },
      "source": [
        "## Connect with Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq5bdOPEakdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/betogaona7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmNyou92atnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faff5804-a971-4f09-b01f-b58958d7b0ce"
      },
      "source": [
        "%cd ./../betogaona7/My\\ Drive/app/Distracted"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/betogaona7/My Drive/app/Distracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh7fTEx2bC32",
        "colab_type": "text"
      },
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL2NkIhYbA0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import random\n",
        "from PIL import Image \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import scipy \n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jSWxOnbbFSn",
        "colab_type": "text"
      },
      "source": [
        "## Create train and validation TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugDfG9V2lT9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imgs_with_labels(src):\n",
        "  data = []\n",
        "  total = 0\n",
        "  for path, subdir, files in os.walk(src):\n",
        "    for file in files:\n",
        "      if file[-3:] == 'jpg': \n",
        "        data.append((os.path.join(path, file), path[-1:]))\n",
        "      total += 1\n",
        "  return data, total\n",
        "\n",
        "data, total = imgs_with_labels(\"./data/test/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owYTFog5vigm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(total)\n",
        "img_path, label = data[random.randint(0, total)]\n",
        "print(\"img: \", img_path, \" label: \", label, \" total: \", total )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi84VKBor1ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data[:10])\n",
        "random.shuffle(data)\n",
        "print(data[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTWaqSYzrkWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = 22424\n",
        "\n",
        "tsize = int(0.8*total)+1\n",
        "vsize = int(0.2*total)\n",
        "\n",
        "train_data = data[:tsize]\n",
        "valid_data = data[-vsize:]\n",
        "\n",
        "print(len(train_data), len(valid_data), tsize+vsize)\n",
        "print(train_data[-10:])\n",
        "print(valid_data[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQSp7kjKl_xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def create_tf_record(tfr_name, data):\n",
        "  writer = tf.python_io.TFRecordWriter(tfr_name)\n",
        "  i = 1\n",
        "  for img_path, img_class in data:\n",
        "    img = np.array(Image.open(img_path))\n",
        "\n",
        "    img_raw = open(img_path, 'rb').read()\n",
        "    label = int(img_class)\n",
        "    path = str.encode(img_path)\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image': _bytes_feature(img_raw),\n",
        "        'label': _int64_feature(label),\n",
        "        'height': _int64_feature(img.shape[0]),\n",
        "        'width': _int64_feature(img.shape[1]),\n",
        "        'depth': _int64_feature(img.shape[2]),\n",
        "        'path': _bytes_feature(path) }))\n",
        "    writer.write(example.SerializeToString())\n",
        "    if(i%100 == 0):\n",
        "        print(i)\n",
        "    i+= 1\n",
        "  writer.close()\n",
        "  \n",
        "#create_tf_record(\"train2.tfrecord\", train_data)\n",
        "#create_tf_record(\"valid2.tfrecord\", valid_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqsWpGPNupua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example in tf.python_io.tf_record_iterator(\"test.tfrecord\"):\n",
        "  result = tf.train.Example.FromString(example)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLl_WRcY3tmt",
        "colab_type": "code",
        "outputId": "87e3df2d-2f4d-4fbd-e76f-42c334717001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!du -lh valid.tfrecord\n",
        "!du -lh train.tfrecord\n",
        "!du -sh ./data/train/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91M\tvalid.tfrecord\n",
            "820M\ttrain.tfrecord\n",
            "913M\t./data/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3QcMMXjA1m3",
        "colab_type": "code",
        "outputId": "ae5d85ba-00a8-42f3-8b4f-8a19c5178cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!du -lh test.tfrecord"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2G\ttest.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvnwbEyO_tvX",
        "colab_type": "text"
      },
      "source": [
        "## Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9bBhMVUplqc",
        "colab_type": "text"
      },
      "source": [
        "### Affine transforms\n",
        "\n",
        "Functions taken from Keras preprocessing [code](https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/affine_transformations.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH8zJRKFl_8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_affine_transform(x, shear=0, zx=1, zy=1, channel_axis=0,\n",
        "                           fill_mode='nearest', cval=0., order=1):\n",
        "    transform_matrix = None\n",
        "\n",
        "    if shear != 0:\n",
        "        shear = np.deg2rad(shear)\n",
        "        shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
        "                                 [0, np.cos(shear), 0],\n",
        "                                 [0, 0, 1]])\n",
        "        if transform_matrix is None:\n",
        "            transform_matrix = shear_matrix\n",
        "        else:\n",
        "            transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
        "\n",
        "    if zx != 1 or zy != 1:\n",
        "        zoom_matrix = np.array([[zx, 0, 0],\n",
        "                                [0, zy, 0],\n",
        "                                [0, 0, 1]])\n",
        "        if transform_matrix is None:\n",
        "            transform_matrix = zoom_matrix\n",
        "        else:\n",
        "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
        "\n",
        "    if transform_matrix is not None:\n",
        "        h, w = x.shape[row_axis], x.shape[col_axis]\n",
        "        transform_matrix = transform_matrix_offset_center(\n",
        "            transform_matrix, h, w)\n",
        "        x = np.rollaxis(x, channel_axis, 0)\n",
        "        final_affine_matrix = transform_matrix[:2, :2]\n",
        "        final_offset = transform_matrix[:2, 2]\n",
        "\n",
        "        channel_images = [ndimage.interpolation.affine_transform(\n",
        "            x_channel,\n",
        "            final_affine_matrix,\n",
        "            final_offset,\n",
        "            order=order,\n",
        "            mode=fill_mode,\n",
        "            cval=cval) for x_channel in x]\n",
        "        x = np.stack(channel_images, axis=0)\n",
        "        x = np.rollaxis(x, 0, channel_axis + 1)\n",
        "return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s056RmMNjYVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_shear(image, intensity):\n",
        "  shear = np.random.uniform(-intensity, intensity)\n",
        "  image = apply_affine_transform(image, shear=shear)\n",
        "  return image\n",
        "\n",
        "def random_zoom(image, zoom_range):\n",
        "  zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
        "  image = apply_affine_transform(image, zx=zx, zy=zy)\n",
        "  return image "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ_UDTCdpzcv",
        "colab_type": "text"
      },
      "source": [
        "### Build the dataset using TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LHNp5RZ8g9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def StateFarmDataset(image_size, tfrecord_file, shuffle_buffer_size, batch_size):\n",
        "  img_size = tf.cast(image_size, tf.int32)\n",
        "  \n",
        "  def _parse_function(example):\n",
        "    features = {'label': tf.FixedLenFeature((), tf.int64),\n",
        "                'image': tf.FixedLenFeature((), tf.string),\n",
        "                'height': tf.FixedLenFeature((), tf.int64),\n",
        "                'width': tf.FixedLenFeature((), tf.int64),\n",
        "                'depth': tf.FixedLenFeature((), tf.int64),\n",
        "                'path': tf.FixedLenFeature((), tf.string)}\n",
        "    parsed_features = tf.parse_single_example(example, features)\n",
        "    \n",
        "    # Reconstruct image \n",
        "    image = tf.image.decode_jpeg(parsed_features['image'], 3)\n",
        "    img_shape = tf.stack([tf.cast(parsed_features['height'], tf.int32),\n",
        "                          tf.cast(parsed_features['width'], tf.int32),\n",
        "                          tf.cast(parsed_features['depth'], tf.int32)])\n",
        "    image = tf.reshape(image, img_shape)\n",
        "    \n",
        "    # Normalize the image in the range 0 to 1\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    # Reshape image \n",
        "    image = tf.image.resize(image, [image_size, image_size])\n",
        "        \n",
        "    # One-hot encoding\n",
        "    label = tf.one_hot(parsed_features['label'], 10, dtype=tf.int32)\n",
        "    \n",
        "    return image, label, parsed_features['path']\n",
        "  \n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "  dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  \n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  \n",
        "  return dataset         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZYHZQOFZ7Y",
        "colab_type": "code",
        "outputId": "04f93429-8ebf-42df-a9d2-ffe2f7234b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = 22424\n",
        "dataset = StateFarmDataset(64, \"train2.tfrecord\", total, 1)\n",
        "print(dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 64, 64, ?), (?, 10), (?,)), types: (tf.float32, tf.int32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobVutrvFu33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_normalization(image):\n",
        "  assert image.max() <= 1 and image.min() >= 0,\\\n",
        "        'Incorect Range. {} to {} found'.format(image().min(), image.to_numpy().max())\n",
        "  print(\"Fine.\")\n",
        "    \n",
        "\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "record = iterator.get_next()\n",
        "with tf.Session() as sess:\n",
        "  img, label, img_path = sess.run(record)\n",
        "  print(\"Label: \", label)\n",
        "  print(\"Img path: \", img_path)\n",
        "  print(\"Img shape: \", img.shape)\n",
        "  test_normalization(img[0])\n",
        "  plt.imshow(img[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mwmueSikRfZ",
        "colab_type": "code",
        "outputId": "2f449909-3cc8-4b83-8aec-e9751f4783ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "train_samples = 20181\n",
        "valid_samples =  2242\n",
        "img_size = 64\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = StateFarmDataset(img_size, \"train.tfrecord\", train_samples, batch_size)\n",
        "valid_dataset = StateFarmDataset(img_size, \"valid.tfrecord\", valid_samples, valid_samples)\n",
        "\n",
        "handle = tf.placeholder(tf.string, shape=[], name=\"handle\")\n",
        "train_iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
        "next_train_elements = train_iterator.get_next()\n",
        "train_iter = train_dataset.make_initializable_iterator()\n",
        "\n",
        "\n",
        "#handle2 = tf.placeholder(tf.string, shape=[])\n",
        "#valid_iterator = tf.data.Iterator.from_string_handle(handle2, valid_dataset.output_types, valid_dataset.output_shapes)\n",
        "#next_valid_elements = valid_iterator.get_next()\n",
        "#valid_iter = valid_dataset.make_initializable_iterator(shared_name=\"iterator\")\n",
        "\n",
        "\n",
        "valid_iterator = valid_dataset.make_one_shot_iterator()\n",
        "next_valid_elements = valid_iterator.get_next()\n",
        "\n",
        "\n",
        "print(\"Samples in training: \", train_samples, \"Number of trainining mini-batches: \", int(train_samples/batch_size)+1)\n",
        "print(\"Samples in validation: \", valid_samples, \"Number of validation mini-batches: \", int(valid_samples/valid_samples))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Samples in training:  20181 Number of trainining mini-batches:  158\n",
            "Samples in validation:  2242 Number of validation mini-batches:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49qUeQAFilxG",
        "colab_type": "text"
      },
      "source": [
        "## Build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ynlm9ICKblS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_input(img_shape):\n",
        "  return tf.placeholder(tf.float32, shape=[None, img_shape[0], img_shape[1], img_shape[2]], name=\"x\")\n",
        "\n",
        "def nn_label(n_classes):\n",
        "  return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
        "\n",
        "def nn_keep_prob():\n",
        "  return tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "def conv2d_maxpool(x_tensor, outs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
        "  weights = tf.Variable(tf.truncated_normal([conv_ksize, conv_ksize, int(x_tensor.shape[3]), outs]))\n",
        "  bias = tf.Variable(tf.zeros([outs]))\n",
        "  \n",
        "  x = tf.nn.conv2d(x_tensor, weights, strides=[1, conv_strides, conv_strides, 1], padding=\"SAME\")\n",
        "  x = tf.nn.bias_add(x, bias)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.nn.max_pool(x, ksize=[1, pool_ksize, pool_ksize, 1], strides=[1, pool_strides, pool_strides, 1], padding=\"SAME\")\n",
        "  return x\n",
        "\n",
        "def flatten(x_tensor):\n",
        "  dimensions = x_tensor.get_shape().as_list()\n",
        "  img_flat_size = dimensions[1] * dimensions[2] * dimensions[3]\n",
        "  return tf.reshape(x_tensor, [-1, img_flat_size])\n",
        "\n",
        "def dense(x_tensor, n_outputs):\n",
        "  weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), n_outputs], mean=0.0, stddev=0.1))\n",
        "  bias = tf.Variable(tf.zeros([n_outputs]))\n",
        "  \n",
        "  x = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "  x = tf.nn.relu(x)\n",
        "  return x\n",
        "\n",
        "def nn_output(x_tensor, n_outputs):\n",
        "  weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), n_outputs], mean=0.0, stddev=0.1))\n",
        "  bias = tf.Variable(tf.zeros([n_outputs]))\n",
        "  \n",
        "  x = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvHqNlk0Msl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(x, keep_prob):\n",
        "  conv1 = conv2d_maxpool(x, 128, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv2 = conv2d_maxpool(conv1, 64, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv3 = conv2d_maxpool(conv2, 32, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  conv4 = conv2d_maxpool(conv3, 16, 3, 1, pool_ksize=2, pool_strides=2)\n",
        "  \n",
        "  fc1 = flatten(conv4)\n",
        "  fc1 = dense(fc1, 1024)\n",
        "  \n",
        "  out = nn_output(fc1, 10)\n",
        "  return out \n",
        "\n",
        "x = nn_input((64, 64, 3))\n",
        "y = nn_label(10)\n",
        "keep_prob = nn_keep_prob()\n",
        "\n",
        "logits = model(x, keep_prob)\n",
        "logits = tf.identity(logits, name=\"logits\")\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DhpKlR55t88",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG3a7xeVlGIi",
        "colab_type": "code",
        "outputId": "40e7a2b3-6fa3-4e4d-fd25-7ed48fe090a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not tf.test.gpu_device_name():\n",
        "  print(\"You don't have the GPU activated\")\n",
        "else:\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJf8zWtV5y_I",
        "colab_type": "text"
      },
      "source": [
        "### Single optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drIDmI3Z3fB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn(session, optimizer, keep_probability, feature_batch, label_batch):\n",
        "  return session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
        "\n",
        "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
        "  loss = sess.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
        "  \n",
        "  valid_acc = sess.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
        "  print(\"Loss: {:>10.4f} Accuracy: {:.6f}\".format(loss, valid_acc))\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZyW-sMz7kH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "keep_probability = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hffgzEaURhp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Checking training on a single mini batch... \")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  train_handle = sess.run(train_iter.string_handle())\n",
        "  sess.run(train_iter.initializer)\n",
        "  \n",
        "  valid_features, valid_labels,_ = sess.run(next_valid_elements)\n",
        "  features, labels, _ = sess.run(next_train_elements, feed_dict={handle: train_handle}) # First mini batch\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    batch_i = 1\n",
        "    train_nn(sess, optimizer, keep_probability, features, labels)\n",
        "    print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "    print_stats(sess, valid_features, valid_labels, cost, accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB7A1SkraOpV",
        "colab_type": "text"
      },
      "source": [
        "## Full train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw-Cv3R4CmyN",
        "colab_type": "code",
        "outputId": "1c477132-42fe-4e8f-e5b3-f812b386c7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print(\"Training...\")\n",
        "\n",
        "with tf.Session() as  sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  train_handle = sess.run(train_iter.string_handle())\n",
        "  #valid_handle = sess.run(valid_iter.string_handle())\n",
        "  \n",
        "  valid_features, valid_labels,_ = sess.run(next_valid_elements)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    sess.run(train_iter.initializer)\n",
        "    for minibatch in range(158):\n",
        "      features, labels, _ = sess.run(next_train_elements, feed_dict={handle: train_handle})\n",
        "      train_nn(sess, optimizer, keep_probability, features, labels)\n",
        "    print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, 1), end='')\n",
        "    print_stats(sess, valid_features, valid_labels, cost, accuracy)\n",
        "    \n",
        "  \"\"\"  \n",
        "  sess.run(valid_iter.initializer)\n",
        "  print(\"\\nValidation average accuracy: \", end='')\n",
        "  total_acc = 0\n",
        "  for minibatch in range(35):\n",
        "    features, labels, _ = sess.run(next_valid_elements, feed_dict={handle2: valid_handle})\n",
        "    valid_acc = sess.run(accuracy, feed_dict={x:features, y:labels, keep_prob:1.})\n",
        "    total_acc += valid_acc\n",
        "  print(\"{:.6f}\".format(total_acc/35))\"\"\"\n",
        "  \n",
        "  saver = tf.train.Saver()\n",
        "  save_path = saver.save(sess, \"./trained-model\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch  1, Batch 1:  Loss:   521.1396 Accuracy: 0.611954\n",
            "Epoch  2, Batch 1:  Loss:   271.5670 Accuracy: 0.748439\n",
            "Epoch  3, Batch 1:  Loss:   133.4597 Accuracy: 0.863515\n",
            "Epoch  4, Batch 1:  Loss:   118.0047 Accuracy: 0.871543\n",
            "Epoch  5, Batch 1:  Loss:    98.8571 Accuracy: 0.892953\n",
            "Epoch  6, Batch 1:  Loss:    97.1895 Accuracy: 0.891615\n",
            "Epoch  7, Batch 1:  Loss:    68.7601 Accuracy: 0.920161\n",
            "Epoch  8, Batch 1:  Loss:    74.7848 Accuracy: 0.916146\n",
            "Epoch  9, Batch 1:  Loss:    79.2344 Accuracy: 0.919715\n",
            "Epoch 10, Batch 1:  Loss:    62.5490 Accuracy: 0.935326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Esg0l5hBBd",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhLo8lCDaFvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example in tf.python_io.tf_record_iterator(\"test.tfrecord\"):\n",
        "  result = tf.train.Example.FromString(example)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w83ldRALcEKv",
        "colab_type": "code",
        "outputId": "df221613-01bf-45d3-e8f9-c568dddcd8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_test_data(image_size, tfrecord_file, batch_size):\n",
        "  img_size = tf.cast(image_size, tf.int32)\n",
        "  \n",
        "  def _parse_function(example):\n",
        "    features = {'image': tf.FixedLenFeature((), tf.string),\n",
        "                'height': tf.FixedLenFeature((), tf.int64),\n",
        "                'width': tf.FixedLenFeature((), tf.int64),\n",
        "                'depth': tf.FixedLenFeature((), tf.int64),\n",
        "                'path': tf.FixedLenFeature((), tf.string)}\n",
        "    parsed_features = tf.parse_single_example(example, features)\n",
        "    \n",
        "    # Reconstruct image \n",
        "    image = tf.image.decode_jpeg(parsed_features['image'], 3)\n",
        "    img_shape = tf.stack([tf.cast(parsed_features['height'], tf.int32),\n",
        "                          tf.cast(parsed_features['width'], tf.int32),\n",
        "                          tf.cast(parsed_features['depth'], tf.int32)])\n",
        "    image = tf.reshape(image, img_shape)\n",
        "    \n",
        "    # Normalize the image in the range 0 to 1\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    # Reshape image \n",
        "    image = tf.image.resize(image, [image_size, image_size])\n",
        "    \n",
        "    return image, parsed_features['path']\n",
        "  \n",
        "  dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  \n",
        "  return dataset        \n",
        "\n",
        "test_data = get_test_data(64, \"test.tfrecord\", 1)\n",
        "print(test_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 64, 64, ?), (?,)), types: (tf.float32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2zXCnKtUTgT",
        "colab_type": "text"
      },
      "source": [
        "### Display a single test image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NThhCDBEUgf2",
        "colab_type": "code",
        "outputId": "885d1344-7b42-4a9a-a772-eb184c458ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "iterator = test_data.make_one_shot_iterator()\n",
        "record = iterator.get_next()\n",
        "with tf.Session() as sess:\n",
        "  img, img_path = sess.run(record)\n",
        "  print(\"Img path: \", img_path)\n",
        "  print(\"Img shape: \", img.shape)\n",
        "  testing_image = img\n",
        "  plt.imshow(img[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Img path:  [b'./test/img_95953.jpg']\n",
            "Img shape:  (1, 64, 64, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nenZQQTBLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2UIVQLfVWQq",
        "colab_type": "text"
      },
      "source": [
        "### Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HI2d5YVZZ-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14f7ed5e-2899-40ca-d7a5-ba0daeddf46d"
      },
      "source": [
        "save_model_path=\"./trained-model\"\n",
        "batch_size = 128\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "rel_graph = tf.Graph()\n",
        "\n",
        "with rel_graph.as_default(): \n",
        "  test_data = get_test_data(64, \"test.tfrecord\", batch_size)\n",
        "  \n",
        "  handle = tf.placeholder(tf.string, shape=[], name=\"handle\")\n",
        "  test_iterator = tf.data.Iterator.from_string_handle(handle, test_data.output_types, test_data.output_shapes)\n",
        "  next_elements = test_iterator.get_next()\n",
        "  test_iter = test_data.make_initializable_iterator()\n",
        "  \n",
        "\n",
        "\n",
        "def get_predictions(loaded_graph, csv_file):\n",
        "  \n",
        "  csvfile = open(csv_file, 'w', newline='')\n",
        "  doc = csv.writer(csvfile)\n",
        "  doc.writerow(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
        "  \n",
        "  #loaded_graph = tf.Graph()\n",
        "  with tf.Session(graph=loaded_graph) as sess:\n",
        "    \n",
        "    # Load model \n",
        "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
        "    loader.restore(sess, save_model_path)\n",
        "    \n",
        "    # Get tensor from loaded model\n",
        "    loaded_x = loaded_graph.get_tensor_by_name(\"x:0\")\n",
        "    loaded_y = loaded_graph.get_tensor_by_name(\"y:0\")\n",
        "    loaded_keep_prob = loaded_graph.get_tensor_by_name(\"keep_prob:0\")\n",
        "    loaded_logits = loaded_graph.get_tensor_by_name(\"logits:0\")\n",
        "    loaded_acc = loaded_graph.get_tensor_by_name(\"accuracy:0\")\n",
        "        \n",
        "    fake_label = np.zeros([1,10], dtype=np.int32)    \n",
        "    \n",
        "    test_handle = sess.run(test_iter.string_handle())\n",
        "    sess.run(test_iter.initializer)\n",
        "    \n",
        "    for minibatch in range(623): #79726/128\n",
        "      imgs, names = sess.run(next_elements, feed_dict={handle: test_handle})\n",
        "      p = sess.run(tf.nn.softmax(loaded_logits), feed_dict={loaded_x: imgs,\n",
        "                                                            loaded_y: fake_label,\n",
        "                                                            loaded_keep_prob: 1.0})\n",
        "      \n",
        "      for i in range(len(imgs)):\n",
        "        doc.writerow([names[i][7:].decode(\"utf-8\"), \n",
        "                      p[i][0], p[i][1], p[i][2], p[i][3], p[i][4], \n",
        "                      p[i][5], p[i][6], p[i][7], p[i][8], p[i][9]])\n",
        "        \n",
        "      if(minibatch%10 == 0):\n",
        "        print(minibatch , \" minibatches tested.\")\n",
        "      imgs, names, p = None, None, None\n",
        "      \n",
        "    csvfile.close()\n",
        "    \n",
        "get_predictions(rel_graph, \"predictions.csv\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "620  minibatches tested.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEcMkFqPs00s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}